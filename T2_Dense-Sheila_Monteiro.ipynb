{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tarefa_2-Primeira_rede_densa_MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k25s8goJIT8u"
      },
      "source": [
        "**O cÃ³digo nessa tarefa foi modificado a partir do tutorial: https://victorzhou.com/blog/keras-neural-network-tutorial/**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wzi83flyixwJ",
        "outputId": "1d4ce252-1266-4ef0-ef68-61617d998f92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 775
        }
      },
      "source": [
        "pip install tensorflow numpy mnist\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (2.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.5)\n",
            "Collecting mnist\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/c4/5db3bfe009f8d71f1d532bbadbd0ec203764bba3a469e4703a889db8e5e0/mnist-0.2.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.32.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.35.1)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.10.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow) (50.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.17.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (2.0.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (3.2.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
            "Installing collected packages: mnist\n",
            "Successfully installed mnist-0.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UBy548TY9An"
      },
      "source": [
        "MNIST is a database of handwritten digits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nffP5FyCgXZY"
      },
      "source": [
        "import numpy as np\n",
        "import mnist\n",
        "from tensorflow import keras\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtq9BLlcZ6JX"
      },
      "source": [
        "Importing train and test datasets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xp25uy7piYZW"
      },
      "source": [
        "train_images = mnist.train_images()\n",
        "train_labels = mnist.train_labels()\n",
        "test_images = mnist.test_images()\n",
        "test_labels = mnist.test_labels()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwNx0d2zEHgs",
        "outputId": "15b0e234-f49e-4060-cde0-a3f35f582e19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "print(train_images[0:2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZqKIZIOa19J"
      },
      "source": [
        "Pixel values varies from 0 to 255, since neural network processeses use small weight values, large inputs can interrupt or slow down the learning process. Therefore, it is a good practice to normalize pixel values: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOZnpojra1MH"
      },
      "source": [
        "# Normalize the images.\n",
        "train_images = (train_images / 255) - 0.5\n",
        "test_images = (test_images / 255) - 0.5\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riX7sDYYnjIl",
        "outputId": "2d50796e-20f1-497a-8caf-11d51f65d2f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(train_images[0].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBDvgcJzmAJ9"
      },
      "source": [
        "Images in the dataset are 28x28 pixels. Each image will be flattened to an array of 784 elements, observe that the transformation doesn't change the image size:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTZ43Zy4iQTM",
        "outputId": "3ac300f5-a95f-4125-fa1d-d7a702e60fa7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# Flatten the images.\n",
        "train_images = train_images.reshape((-1, 784))  \n",
        "test_images = test_images.reshape((-1, 784))\n",
        "\n",
        "print(train_images.shape) # (60000, 784)\n",
        "print(test_images.shape)  # (10000, 784)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n",
            "(10000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBVyQOpi0ayj"
      },
      "source": [
        "The Sequential model, from Tensorflow-Keras  library, is a linear stack of layers, which means that the output of one layer is the input of the layer below. The input shape needs to be specified on the first layer from our model. It corresponds to flattened image's shape (784): "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7i9j4f6lPAE"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout\n",
        "\n",
        "# Still a WIP\n",
        "model = Sequential([\n",
        "  Dense(64, activation='relu',input_shape=(784,)),\n",
        "  Dropout(0.2),\n",
        "  Dense(64, activation='relu'),\n",
        "  Dropout(0.2),\n",
        "  Dense(10, activation='softmax'),\n",
        "])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLRJXyK2_HGA"
      },
      "source": [
        "64 is the number of nodes, and the dimensionality of the output space. The last layer has output dimensionality 10, one for each digit (0 to 9). Next, we must compile our model. This step is responsible for configuring the training process: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlbopN75nK2G"
      },
      "source": [
        "model.compile(\n",
        "  optimizer='adam',\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy'],\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHHZwZOpkdTk"
      },
      "source": [
        "**Optimizer -** responsible for changing attributes, such as learning rate and weights, from the neural network in order to minimize the loss.\n",
        "\n",
        "**loss -** measures the performance of a model. Since we use Softmax activation function as output in our model, we choose the categorical crossentropy loss function because it measures the performance of a model whose output is a probability value between 0 and 1.  \n",
        "\n",
        "**metrics -** there are a variety of metrics used to evaluate a model. The one used in this example is accuracy, used to evaluate classification models.  \n",
        "\n",
        "# **Training the model**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmapWuxynbBM",
        "outputId": "cf3be38d-c5a3-4a4f-9821-444bd16ee575",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "model.fit(\n",
        "  train_images,\n",
        "  to_categorical(train_labels),\n",
        "  epochs=8, #inicial 5\n",
        "  batch_size=50,  #inicial 32\n",
        ")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "1200/1200 [==============================] - 2s 2ms/step - loss: 0.5690 - accuracy: 0.8210\n",
            "Epoch 2/8\n",
            "1200/1200 [==============================] - 2s 2ms/step - loss: 0.3388 - accuracy: 0.8962\n",
            "Epoch 3/8\n",
            "1200/1200 [==============================] - 2s 2ms/step - loss: 0.2860 - accuracy: 0.9122\n",
            "Epoch 4/8\n",
            "1200/1200 [==============================] - 2s 2ms/step - loss: 0.2608 - accuracy: 0.9186\n",
            "Epoch 5/8\n",
            "1200/1200 [==============================] - 2s 2ms/step - loss: 0.2470 - accuracy: 0.9246\n",
            "Epoch 6/8\n",
            "1200/1200 [==============================] - 2s 2ms/step - loss: 0.2328 - accuracy: 0.9290\n",
            "Epoch 7/8\n",
            "1200/1200 [==============================] - 2s 2ms/step - loss: 0.2197 - accuracy: 0.9330\n",
            "Epoch 8/8\n",
            "1200/1200 [==============================] - 2s 2ms/step - loss: 0.2161 - accuracy: 0.9354\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f61af9d8d68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUuActW1T5vz"
      },
      "source": [
        "\n",
        "\n",
        "# **Evaluating the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHOTmkshoe-_",
        "outputId": "3f7bfc06-95cd-461e-82ba-5dbed1d0e3b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "model.evaluate(\n",
        "  test_images,\n",
        "  to_categorical(test_labels)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 0s 947us/step - loss: 0.1385 - accuracy: 0.9586\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1384877860546112, 0.9585999846458435]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0TRbYrzrbm6"
      },
      "source": [
        "# **Using the Model**\n",
        "\n",
        "Saving weights:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wjr3fuEHrwG0"
      },
      "source": [
        "model.save_weights('/content/drive/My Drive/Colab Notebooks/DL/Ex_1/model.h5') #saving model to disk\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efmCWWRDkeo6"
      },
      "source": [
        "Loading layer weights, either from a TensorFlow or an HDF5 weight file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7l9gft-SsDmX"
      },
      "source": [
        "# Load the model's saved weights.\n",
        "model.load_weights('model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNiYZO7QkkTE"
      },
      "source": [
        "# **Making predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ts8iKhtRsWyL",
        "outputId": "82ccda18-3289-470a-f992-3d9d97abca1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# Predict on the first 5 test images.\n",
        "predictions = model.predict(test_images[:5])\n",
        "\n",
        "# Print our model's predictions.\n",
        "print(np.argmax(predictions, axis=1)) # [7, 2, 1, 0, 4]\n",
        "\n",
        "# Check our predictions against the ground truths.\n",
        "print(test_labels[:5]) # [7, 2, 1, 0, 4]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[7 2 1 0 4]\n",
            "[7 2 1 0 4]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}